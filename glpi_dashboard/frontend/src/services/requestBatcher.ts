/**
 * Sistema de batching de requisi√ß√µes para agrupar m√∫ltiplas chamadas
 * em uma √∫nica requisi√ß√£o, reduzindo a carga no servidor
 */

interface BatchRequest {
  id: string;
  endpoint: string;
  params: any;
  resolve: (data: any) => void;
  reject: (error: any) => void;
  timestamp: number;
}

interface BatchConfig {
  maxBatchSize: number;
  maxWaitTime: number;
  endpoints: string[];
}

class RequestBatcher {
  private pendingRequests = new Map<string, BatchRequest[]>();
  private batchTimers = new Map<string, NodeJS.Timeout>();
  private config: BatchConfig;

  constructor(config: Partial<BatchConfig> = {}) {
    this.config = {
      maxBatchSize: 10,
      maxWaitTime: 100, // 100ms
      endpoints: ['metrics', 'tickets', 'users'],
      ...config,
    };
  }

  /**
   * Adiciona uma requisi√ß√£o ao batch ou executa imediatamente se n√£o for batch√°vel
   */
  async batchRequest<T>(
    endpoint: string,
    params: any = {},
    fetchFn: (batchedParams: any[]) => Promise<T[]>
  ): Promise<T> {
    // Verificar se o endpoint suporta batching
    if (!this.config.endpoints.includes(endpoint)) {
      // Executar requisi√ß√£o individual
      const result = await fetchFn([params]);
      return result[0];
    }

    return new Promise<T>((resolve, reject) => {
      const requestId = this.generateRequestId();
      const batchKey = this.getBatchKey(endpoint);

      const request: BatchRequest = {
        id: requestId,
        endpoint,
        params,
        resolve,
        reject,
        timestamp: Date.now(),
      };

      // Adicionar √† lista de requisi√ß√µes pendentes
      if (!this.pendingRequests.has(batchKey)) {
        this.pendingRequests.set(batchKey, []);
      }

      const requests = this.pendingRequests.get(batchKey)!;
      requests.push(request);

      console.log(
        `üì¶ Batcher: Adicionada requisi√ß√£o ${requestId} ao batch ${batchKey} (${requests.length}/${this.config.maxBatchSize})`
      );

      // Verificar se deve executar o batch imediatamente
      if (requests.length >= this.config.maxBatchSize) {
        this.executeBatch(batchKey, fetchFn);
      } else {
        // Configurar timer se n√£o existir
        if (!this.batchTimers.has(batchKey)) {
          const timer = setTimeout(() => {
            this.executeBatch(batchKey, fetchFn);
          }, this.config.maxWaitTime);

          this.batchTimers.set(batchKey, timer);
        }
      }
    });
  }

  /**
   * Executa um batch de requisi√ß√µes
   */
  private async executeBatch<T>(
    batchKey: string,
    fetchFn: (batchedParams: any[]) => Promise<T[]>
  ): Promise<void> {
    const requests = this.pendingRequests.get(batchKey);
    if (!requests || requests.length === 0) {
      return;
    }

    // Limpar timer e requisi√ß√µes pendentes
    const timer = this.batchTimers.get(batchKey);
    if (timer) {
      clearTimeout(timer);
      this.batchTimers.delete(batchKey);
    }

    this.pendingRequests.delete(batchKey);

    console.log(`üöÄ Batcher: Executando batch ${batchKey} com ${requests.length} requisi√ß√µes`);

    try {
      // Extrair par√¢metros de todas as requisi√ß√µes
      const batchedParams = requests.map(req => req.params);

      // Executar requisi√ß√£o em batch
      const startTime = Date.now();
      const results = await fetchFn(batchedParams);
      const duration = Date.now() - startTime;

      console.log(`‚úÖ Batcher: Batch ${batchKey} conclu√≠do em ${duration}ms`);

      // Resolver cada requisi√ß√£o individual com seu resultado correspondente
      requests.forEach((request, index) => {
        if (results[index] !== undefined) {
          request.resolve(results[index]);
        } else {
          request.reject(new Error(`Resultado n√£o encontrado para √≠ndice ${index}`));
        }
      });
    } catch (error) {
      console.error(`‚ùå Batcher: Erro no batch ${batchKey}:`, error);

      // Rejeitar todas as requisi√ß√µes do batch
      requests.forEach(request => {
        request.reject(error);
      });
    }
  }

  /**
   * Gera uma chave √∫nica para agrupar requisi√ß√µes similares
   */
  private getBatchKey(endpoint: string): string {
    return `batch-${endpoint}`;
  }

  /**
   * Gera um ID √∫nico para cada requisi√ß√£o
   */
  private generateRequestId(): string {
    return `req-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
  }

  /**
   * For√ßa a execu√ß√£o de todos os batches pendentes
   */
  async flushAll(): Promise<void> {
    const batchKeys = Array.from(this.pendingRequests.keys());

    for (const batchKey of batchKeys) {
      // Para flush, precisamos de uma fun√ß√£o fetch gen√©rica
      // Isso ser√° implementado quando integrarmos com o sistema de API
      console.log(`üîÑ Batcher: Flushing batch ${batchKey}`);
    }
  }

  /**
   * Obt√©m estat√≠sticas do batcher
   */
  getStats() {
    const totalPending = Array.from(this.pendingRequests.values()).reduce(
      (sum, requests) => sum + requests.length,
      0
    );

    const batchInfo = Array.from(this.pendingRequests.entries()).map(([key, requests]) => ({
      batchKey: key,
      pendingCount: requests.length,
      oldestRequest: Math.min(...requests.map(r => r.timestamp)),
    }));

    return {
      totalPendingRequests: totalPending,
      activeBatches: this.pendingRequests.size,
      activeTimers: this.batchTimers.size,
      batchDetails: batchInfo,
      config: this.config,
    };
  }

  /**
   * Limpa todos os batches pendentes
   */
  clear(): void {
    // Limpar timers
    for (const timer of this.batchTimers.values()) {
      clearTimeout(timer);
    }
    this.batchTimers.clear();

    // Rejeitar todas as requisi√ß√µes pendentes
    for (const requests of this.pendingRequests.values()) {
      requests.forEach(request => {
        request.reject(new Error('Batch cancelado'));
      });
    }
    this.pendingRequests.clear();

    console.log('üßπ Batcher: Todos os batches foram limpos');
  }
}

// Inst√¢ncia singleton do batcher
export const requestBatcher = new RequestBatcher({
  maxBatchSize: 5,
  maxWaitTime: 150, // 150ms para dar tempo de agrupar requisi√ß√µes
  endpoints: ['metrics', 'tickets', 'users', 'ranking'],
});

/**
 * Fun√ß√£o auxiliar para criar requisi√ß√µes em batch para m√©tricas
 */
export const batchMetricsRequest = async (params: any) => {
  return requestBatcher.batchRequest('metrics', params, async (batchedParams: any[]) => {
    // Implementar l√≥gica de requisi√ß√£o em batch para m√©tricas
    // Por enquanto, fazemos requisi√ß√µes individuais
    const results: any[] = [];
    for (const param of batchedParams) {
      try {
        const response = await fetch(`/api/metrics?${new URLSearchParams(param)}`);
        const data = await response.json();
        results.push(data as any);
      } catch (error) {
        results.push(null as any);
      }
    }
    return results;
  });
};

/**
 * Fun√ß√£o auxiliar para criar requisi√ß√µes em batch para tickets
 */
export const batchTicketsRequest = async (params: any) => {
  return requestBatcher.batchRequest('tickets', params, async (batchedParams: any[]) => {
    // Implementar l√≥gica de requisi√ß√£o em batch para tickets
    const results: any[] = [];
    for (const param of batchedParams) {
      try {
        const response = await fetch(`/api/tickets?${new URLSearchParams(param)}`);
        const data = await response.json();
        results.push(data as any);
      } catch (error) {
        results.push(null as any);
      }
    }
    return results;
  });
};

// Configurar limpeza autom√°tica em caso de erro
window.addEventListener('beforeunload', () => {
  requestBatcher.clear();
});
