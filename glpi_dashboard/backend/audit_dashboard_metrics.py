#!/usr/bin/env python3
"""
Script de Auditoria do Dashboard GLPI
Realiza testes exaustivos para identificar inconsistÃªncias nas mÃ©tricas
"""

import json
import logging
import time
from datetime import datetime, timedelta

import requests

from backend.config.settings import active_config
from backend.services.glpi_service import GLPIService

# Configurar logging
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class DashboardAuditor:
    def __init__(self):
        self.base_url = "http://localhost:5000/api"
        self.glpi_service = GLPIService()
        self.results = {}

    def test_api_endpoints(self):
        """Testa todos os endpoints da API relacionados Ã s mÃ©tricas"""
        print("\n=== TESTE DOS ENDPOINTS DA API ===")

        endpoints = [
            "/metrics",
            "/metrics/simple",
            "/metrics/filtered",
            "/status",
            "/test",
        ]

        for endpoint in endpoints:
            print(f"\nğŸ” Testando endpoint: {endpoint}")
            try:
                response = requests.get(f"{self.base_url}{endpoint}", timeout=30)
                print(f"  Status: {response.status_code}")

                if response.status_code == 200:
                    data = response.json()
                    print(f"  Sucesso: {data.get('success', 'N/A')}")

                    if endpoint == "/metrics":
                        self.analyze_metrics_response(data)
                    elif endpoint == "/metrics/simple":
                        self.analyze_simple_metrics(data)

                else:
                    print(f"  âŒ Erro: {response.text}")

            except Exception as e:
                print(f"  âŒ ExceÃ§Ã£o: {e}")

    def analyze_metrics_response(self, data):
        """Analisa a resposta do endpoint /metrics"""
        print("\nğŸ“Š ANÃLISE DA RESPOSTA /metrics:")

        if not data.get("success"):
            print(
                f"  âŒ API retornou success=False: {data.get('message', 'Sem mensagem')}"
            )
            return

        metrics = data.get("data", {})

        # Verificar mÃ©tricas gerais
        geral = metrics.get("niveis", {}).get("geral", {})
        print(f"  ğŸ“ˆ MÃ©tricas Gerais:")
        print(f"    - Novos: {geral.get('novos', 0)}")
        print(f"    - Em Progresso: {geral.get('progresso', 0)}")
        print(f"    - Pendentes: {geral.get('pendentes', 0)}")
        print(f"    - Resolvidos: {geral.get('resolvidos', 0)}")
        print(f"    - Total: {geral.get('total', 0)}")

        # Verificar se todos sÃ£o zero
        if all(
            geral.get(key, 0) == 0
            for key in ["novos", "progresso", "pendentes", "resolvidos"]
        ):
            print("  âš ï¸ PROBLEMA: Todas as mÃ©tricas gerais estÃ£o zeradas!")

        # Verificar mÃ©tricas por nÃ­vel
        niveis = metrics.get("niveis", {})
        for nivel in ["n1", "n2", "n3", "n4"]:
            nivel_data = niveis.get(nivel, {})
            total_nivel = sum(
                nivel_data.get(key, 0)
                for key in ["novos", "progresso", "pendentes", "resolvidos"]
            )
            print(f"  ğŸ“Š {nivel.upper()}: Total = {total_nivel}")

        self.results["api_metrics"] = metrics

    def analyze_simple_metrics(self, data):
        """Analisa a resposta do endpoint /metrics/simple"""
        print("\nğŸ“Š ANÃLISE DA RESPOSTA /metrics/simple:")

        if data.get("success"):
            simple_data = data.get("data", {})
            print(f"  ğŸ“ˆ Dados de Teste:")
            print(f"    - Novos: {simple_data.get('novos', 0)}")
            print(f"    - Em Progresso: {simple_data.get('progresso', 0)}")
            print(f"    - Pendentes: {simple_data.get('pendentes', 0)}")
            print(f"    - Resolvidos: {simple_data.get('resolvidos', 0)}")
            print(f"    - Total: {simple_data.get('total', 0)}")
        else:
            print("  âŒ Endpoint de teste simples falhou")

    def test_glpi_service_direct(self):
        """Testa o GLPIService diretamente"""
        print("\n=== TESTE DIRETO DO GLPI SERVICE ===")

        try:
            # Autenticar
            print("ğŸ” Autenticando no GLPI...")
            if self.glpi_service.authenticate():
                print("  âœ… AutenticaÃ§Ã£o bem-sucedida")
            else:
                print("  âŒ Falha na autenticaÃ§Ã£o")
                return

            # Testar mÃ©todo principal de mÃ©tricas
            print("\nğŸ“Š Testando get_dashboard_metrics()...")
            metrics = self.glpi_service.get_dashboard_metrics()

            if metrics:
                print("  âœ… MÃ©tricas obtidas com sucesso")
                self.analyze_direct_metrics(metrics)
            else:
                print("  âŒ Nenhuma mÃ©trica retornada")

            # Testar contagem direta de tickets
            print("\nğŸ« Testando contagem direta de tickets...")
            self.test_direct_ticket_counts()

        except Exception as e:
            print(f"  âŒ Erro no teste direto: {e}")
            logger.exception("Erro detalhado:")

    def analyze_direct_metrics(self, metrics):
        """Analisa mÃ©tricas obtidas diretamente do serviÃ§o"""
        print("\nğŸ“ˆ ANÃLISE DAS MÃ‰TRICAS DIRETAS:")

        if isinstance(metrics, dict):
            if "data" in metrics:
                data = metrics["data"]
            else:
                data = metrics

            # Verificar estrutura
            if "niveis" in data:
                niveis = data["niveis"]
                geral = niveis.get("geral", {})

                print(f"  ğŸ“Š MÃ©tricas Gerais (Diretas):")
                print(f"    - Novos: {geral.get('novos', 0)}")
                print(f"    - Em Progresso: {geral.get('progresso', 0)}")
                print(f"    - Pendentes: {geral.get('pendentes', 0)}")
                print(f"    - Resolvidos: {geral.get('resolvidos', 0)}")
                print(f"    - Total: {geral.get('total', 0)}")

                # Comparar com resultados da API
                if "api_metrics" in self.results:
                    self.compare_metrics(self.results["api_metrics"], data)

            self.results["direct_metrics"] = data

    def test_direct_ticket_counts(self):
        """Testa contagem direta de tickets por status"""
        print("\nğŸ”¢ CONTAGEM DIRETA DE TICKETS:")

        try:
            # Buscar todos os tickets sem filtro
            print("  ğŸ“‹ Buscando todos os tickets...")
            all_tickets = self.glpi_service.search_items(
                "Ticket", {"range": "0-50", "criteria": []}
            )  # Limitar para teste

            if all_tickets:
                print(f"    âœ… {len(all_tickets)} tickets encontrados (amostra)")

                # Contar por status
                status_counts = {}
                for ticket in all_tickets:
                    status = ticket.get("12", "Desconhecido")  # Campo 12 = status
                    status_counts[status] = status_counts.get(status, 0) + 1

                print("    ğŸ“Š Contagem por Status:")
                for status, count in status_counts.items():
                    print(f"      - {status}: {count}")

                self.results["direct_ticket_counts"] = status_counts

            else:
                print("    âŒ Nenhum ticket encontrado")

        except Exception as e:
            print(f"    âŒ Erro na contagem direta: {e}")

    def test_technician_ranking(self):
        """Testa o ranking de tÃ©cnicos"""
        print("\n=== TESTE DO RANKING DE TÃ‰CNICOS ===")

        try:
            # Testar endpoint de ranking
            print("ğŸ† Testando endpoint /ranking...")
            response = requests.get(f"{self.base_url}/ranking", timeout=30)

            if response.status_code == 200:
                data = response.json()
                print(f"  âœ… Status: {response.status_code}")

                if data.get("success"):
                    ranking = data.get("data", [])
                    print(f"  ğŸ“Š {len(ranking)} tÃ©cnicos no ranking")

                    # Analisar top 5
                    for i, tech in enumerate(ranking[:5]):
                        print(
                            f"    {i+1}. {tech.get('name', 'N/A')}: {tech.get('total', 0)} tickets"
                        )

                    # Verificar se os nÃºmeros estÃ£o muito baixos
                    if ranking:
                        max_tickets = max(tech.get("total", 0) for tech in ranking)
                        if max_tickets < 100:  # Threshold arbitrÃ¡rio
                            print(
                                f"  âš ï¸ PROBLEMA: Maior nÃºmero de tickets Ã© apenas {max_tickets}"
                            )

                else:
                    print(f"  âŒ API retornou success=False: {data.get('message')}")
            else:
                print(f"  âŒ Erro HTTP: {response.status_code}")

        except Exception as e:
            print(f"  âŒ Erro no teste de ranking: {e}")

    def compare_metrics(self, api_data, direct_data):
        """Compara mÃ©tricas da API com mÃ©tricas diretas"""
        print("\nğŸ” COMPARAÃ‡ÃƒO API vs DIRETO:")

        api_geral = api_data.get("niveis", {}).get("geral", {})
        direct_geral = direct_data.get("niveis", {}).get("geral", {})

        for metric in ["novos", "progresso", "pendentes", "resolvidos", "total"]:
            api_val = api_geral.get(metric, 0)
            direct_val = direct_geral.get(metric, 0)

            if api_val == direct_val:
                print(f"  âœ… {metric}: {api_val} (iguais)")
            else:
                print(f"  âš ï¸ {metric}: API={api_val}, Direto={direct_val} (DIFERENTE)")

    def generate_summary_report(self):
        """Gera relatÃ³rio resumo da auditoria"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ RELATÃ“RIO RESUMO DA AUDITORIA")
        print("=" * 60)

        # Problemas identificados
        problems = []

        # Verificar mÃ©tricas zeradas
        if "api_metrics" in self.results:
            geral = self.results["api_metrics"].get("niveis", {}).get("geral", {})
            if all(
                geral.get(key, 0) == 0
                for key in ["novos", "progresso", "pendentes", "resolvidos"]
            ):
                problems.append("âŒ MÃ©tricas gerais do dashboard estÃ£o todas zeradas")

        # Verificar inconsistÃªncias
        if "api_metrics" in self.results and "direct_metrics" in self.results:
            api_geral = self.results["api_metrics"].get("niveis", {}).get("geral", {})
            direct_geral = (
                self.results["direct_metrics"].get("niveis", {}).get("geral", {})
            )

            for metric in ["novos", "progresso", "pendentes", "resolvidos"]:
                if api_geral.get(metric, 0) != direct_geral.get(metric, 0):
                    problems.append(f"âš ï¸ InconsistÃªncia em {metric}: API vs Direto")

        # Exibir problemas
        if problems:
            print("\nğŸš¨ PROBLEMAS IDENTIFICADOS:")
            for problem in problems:
                print(f"  {problem}")
        else:
            print("\nâœ… Nenhum problema crÃ­tico identificado")

        # RecomendaÃ§Ãµes
        print("\nğŸ’¡ RECOMENDAÃ‡Ã•ES:")
        if problems:
            print("  1. Verificar logs do backend para erros de conexÃ£o com GLPI")
            print("  2. Validar configuraÃ§Ãµes de autenticaÃ§Ã£o")
            print("  3. Testar queries SQL diretamente no banco GLPI")
            print("  4. Verificar cache da aplicaÃ§Ã£o")
            print("  5. Analisar filtros de data aplicados")
        else:
            print("  1. Sistema aparenta estar funcionando corretamente")
            print("  2. Continuar monitoramento regular")


if __name__ == "__main__":
    print("ğŸ” Iniciando Auditoria do Dashboard GLPI")
    print(f"â° Timestamp: {datetime.now()}")

    auditor = DashboardAuditor()

    # Executar todos os testes
    auditor.test_api_endpoints()
    auditor.test_glpi_service_direct()
    auditor.test_technician_ranking()

    # Gerar relatÃ³rio final
    auditor.generate_summary_report()

    print("\nğŸ Auditoria concluÃ­da!")
